{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2daf6-01ae-457a-9eaa-62eb9504d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/run-llama/llama_parse/blob/main/examples/demo_advanced.ipynb\n",
    "# https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/llms/llama-index-llms-huggingface/llama_index/llms/huggingface/base.py\n",
    "\n",
    "import pickle\n",
    "import arxiv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "REFRESH_DOCUMENTS = False\n",
    "\n",
    "llm_model_name = \"openai-community/gpt2\"\n",
    "# llm_model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# llm_model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "embed_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "# embed_model_name\"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "reranker_model_name = \"BAAI/bge-reranker-base\"\n",
    "# reranker_model_name = \"BAAI/bge-reranker-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c18d6-0199-49cb-8c3b-515d6c02ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "\n",
    "embedding = embed.get_text_embedding(\"Hello World!\")\n",
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807790d2-5a98-41b2-8000-7f2ba9b23e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=1024,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"do_sample\": False},\n",
    "    # system_prompt=system_prompt,\n",
    "    # query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=llm_model_name,\n",
    "    model_name=llm_model_name,\n",
    "    device_map=\"auto\",\n",
    "    tokenizer_kwargs={\"max_length\": 1024},\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8937ac-dbc7-41e1-b8a8-e52165994e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e256de9-4f0b-4f52-af37-bc0f383999bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DOCUMENTS:\n",
    "    # download pdfs from arxiv\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(\n",
    "      query = \"machine learning\",\n",
    "      max_results = 10,\n",
    "      sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    for r in client.results(search):\n",
    "        r.download_pdf(dirpath=\"./documents\")\n",
    "\n",
    "    # parse pdfs using llama-parse\n",
    "    parser = LlamaParse(\n",
    "        api_key=\"llx-enXNU9nW03mL7suZOnHjTBm3oEMQZrW1bfrKoV7pWA486uOJ\",\n",
    "        result_type=\"markdown\", # \"markdown\" and \"text\" are available\n",
    "        verbose=True\n",
    "    )\n",
    "    file_extractor = {\".pdf\": parser}\n",
    "    reader = SimpleDirectoryReader(\"./documents\", file_extractor=file_extractor)\n",
    "    documents = reader.load_data(num_workers=4)\n",
    "\n",
    "    # save parsed documents to disk\n",
    "    with open('output/documents.pkl', 'wb') as f:\n",
    "        pickle.dump(documents, f)\n",
    "else:\n",
    "    with open('output/documents.pkl', 'rb') as f:\n",
    "        documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299bb6a-49fe-4455-a2f6-878a26849dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b577f7a-4467-4841-bc93-fc8ed6b69116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].text[:1000] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb4a76-7767-4679-b17e-d29e8274e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbea8fc-60f6-4b00-9614-4a8f0a5d066f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 - Deep Learning",
   "language": "python",
   "name": "deep_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
